{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "# 2. Remove Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# 3. Stemming\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# 4. Vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"Hello ram how are you. Did you watch the yesterday cricket match ?\",\n",
    "    \"In yesterday's cricket match virat kohli scored a century and rohit also scored a century\",\n",
    "    \"virat kohli is now the captain of indian cricket team because he played very well and bought us to number one position\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'ram', 'how', 'are', 'you', '.', 'Did', 'you', 'watch', 'the', 'yesterday', 'cricket', 'match', '?']\n",
      "['In', 'yesterday', \"'s\", 'cricket', 'match', 'virat', 'kohli', 'scored', 'a', 'century', 'and', 'rohit', 'also', 'scored', 'a', 'century']\n",
      "['virat', 'kohli', 'is', 'now', 'the', 'captain', 'of', 'indian', 'cricket', 'team', 'because', 'he', 'played', 'very', 'well', 'and', 'bought', 'us', 'to', 'number', 'one', 'position']\n"
     ]
    }
   ],
   "source": [
    "# 1. Tokenization\n",
    "print(word_tokenize(data[0]))\n",
    "print(word_tokenize(data[1]))\n",
    "print(word_tokenize(data[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for i in range(len(data)):\n",
    "    tokens.append(word_tokenize(data[i].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Removing Stopwords\n",
    "engStopwords = stopwords.words('english')\n",
    "engStopwords.extend(['.','?',\"'s\",\"also\",\",\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = []\n",
    "for tokenList in tokens:\n",
    "    t = []\n",
    "    for token in tokenList:\n",
    "        if token not in engStopwords:\n",
    "            t.append(token)\n",
    "    wordList.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', 'ram', 'watch', 'yesterday', 'cricket', 'match'],\n",
       " ['yesterday',\n",
       "  'cricket',\n",
       "  'match',\n",
       "  'virat',\n",
       "  'kohli',\n",
       "  'scored',\n",
       "  'century',\n",
       "  'rohit',\n",
       "  'scored',\n",
       "  'century'],\n",
       " ['virat',\n",
       "  'kohli',\n",
       "  'captain',\n",
       "  'indian',\n",
       "  'cricket',\n",
       "  'team',\n",
       "  'played',\n",
       "  'well',\n",
       "  'bought',\n",
       "  'us',\n",
       "  'number',\n",
       "  'one',\n",
       "  'position']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Stemming\n",
    "# ps = PorterStemmer()\n",
    "wnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wordList)):\n",
    "    for j in range(len(wordList[i])):\n",
    "#         print(\"Actual : {}, Stem : {}\".format(wordList[i][j],wnet.lemmatize(wordList[i][j], pos='v')))\n",
    "        wordList[i][j] = wnet.lemmatize(wordList[i][j], pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wordList)):\n",
    "    wordList[i] = ' '.join(wordList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virat kohli captain indian cricket team play well buy us number one position'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordList[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 4, 'ram': 12, 'watch': 18, 'yesterday': 20, 'cricket': 3, 'match': 7, 'virat': 17, 'kohli': 6, 'score': 14, 'century': 2, 'rohit': 13, 'captain': 1, 'indian': 5, 'team': 15, 'play': 10, 'well': 19, 'buy': 0, 'us': 16, 'number': 8, 'one': 9, 'position': 11}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = cv.transform(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x21 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 2, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello ram watch yesterday cricket match',\n",
       " 'yesterday cricket match virat kohli score century rohit score century',\n",
       " 'virat kohli captain indian cricket team play well buy us number one position']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = cv.fit_transform(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 2, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vect = tfidf.fit_transform(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.27824521, 0.4711101 ,\n",
       "        0.        , 0.        , 0.35829137, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4711101 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4711101 , 0.        ,\n",
       "        0.35829137],\n",
       "       [0.        , 0.        , 0.58564651, 0.17294613, 0.        ,\n",
       "        0.        , 0.22269963, 0.22269963, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29282326, 0.58564651,\n",
       "        0.        , 0.        , 0.22269963, 0.        , 0.        ,\n",
       "        0.22269963],\n",
       "       [0.2948118 , 0.2948118 , 0.        , 0.1741206 , 0.        ,\n",
       "        0.2948118 , 0.22421198, 0.        , 0.2948118 , 0.2948118 ,\n",
       "        0.2948118 , 0.2948118 , 0.        , 0.        , 0.        ,\n",
       "        0.2948118 , 0.2948118 , 0.22421198, 0.        , 0.2948118 ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
